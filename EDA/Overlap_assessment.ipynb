{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3987c2de-b6c1-4340-8d79-666d9ff8e8e4",
   "metadata": {},
   "source": [
    "# Datasets Overlap Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5145769a-4be2-4113-a3bc-5858de24ef85",
   "metadata": {},
   "source": [
    "#### Here we will collect the number of images per class per dataset and analyze overlap.\n",
    "From mapping, we know neither CIFAR-100 or ImageNet-1000 have Wasp or Moquito, additionally, CIFAR-100 does not have Ant, Dragonfly, Fly, Grasshopper, Ladybug. \n",
    "Class overlap:\n",
    "- Clean: 11 classes\n",
    "- CIFAR-100: 4 of the clean classes map (4 fine matches)\n",
    "- ImageNet-1000: 9 of the clean classes map (27 fine matches)\n",
    "- iNaturalist (36k): 9 of the clean classes map (35 fine matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e9a21be-bacb-498f-82b1-d9af17a9226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "#from utils.label_mappings import *\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfc4b5f-3218-420e-b1e9-fdf3b205caf5",
   "metadata": {},
   "source": [
    "### CIFAR-100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d9a4233-724a-4976-8639-0cdf6766b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100 = load_dataset(\"uoft-cs/cifar100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31c55c8a-0bd4-47fd-95ca-e26a977c0599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['img', 'fine_label', 'coarse_label'],\n",
       "    num_rows: 50000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar100['train']  # want to match cifar schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cffc4389-2305-43fe-bb30-2a850e3aa026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
       " 'fine_label': 19,\n",
       " 'coarse_label': 11}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar100['train'][0]  # want image type to be same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8966b1-0474-446b-bb67-0119ed7e5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_df = pd.DataFrame({'fine_label': cifar100['train']['fine_label']})\n",
    "def map_cifar100_to_clean_label(label):\n",
    "    if label in cifar100_to_clean_map:\n",
    "        return cifar100_to_clean_map[label]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "cifar100_df['clean_label'] = cifar100_df['fine_label'].apply(map_cifar100_to_clean_label)\n",
    "cifar100_df.groupby('clean_label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c7056-6efd-45de-a627-5c2e396914d6",
   "metadata": {},
   "source": [
    "### Clean insect validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177ddb81-6efc-456a-8168-6b7853a70a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "base_path = '../clean_insect_images/'\n",
    "\n",
    "class_dirs = ['Ant','Bee','Butterfly','Dragonfly','Fly','Grasshopper','Ladybug','Spider']\n",
    "\n",
    "clean_ds = {'image':[], 'label':[], 'file_path':[]}\n",
    "\n",
    "for c in class_dirs:\n",
    "    target_dir = os.path.join(base_path, c)\n",
    "    image_files = os.listdir(target_dir)\n",
    "    for f in image_files:\n",
    "        full_image_path = os.path.join(target_dir, f)\n",
    "        clean_ds['image'].append(Image.open(full_image_path))\n",
    "        clean_ds['label'].append(c)\n",
    "        clean_ds['file_path'].append(full_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16426ccd-e2da-4d23-936c-e8ac83a88439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ant</td>\n",
       "      <td>../clean_insect_images/Ant/Ant_472.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ant</td>\n",
       "      <td>../clean_insect_images/Ant/Ant_13.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ant</td>\n",
       "      <td>../clean_insect_images/Ant/Ant_719.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ant</td>\n",
       "      <td>../clean_insect_images/Ant/Ant_378.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ant</td>\n",
       "      <td>../clean_insect_images/Ant/Ant_641.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6313</th>\n",
       "      <td>Spider</td>\n",
       "      <td>../clean_insect_images/Spider/Spider_376.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6314</th>\n",
       "      <td>Spider</td>\n",
       "      <td>../clean_insect_images/Spider/Spider_400.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6315</th>\n",
       "      <td>Spider</td>\n",
       "      <td>../clean_insect_images/Spider/Spider_558.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6316</th>\n",
       "      <td>Spider</td>\n",
       "      <td>../clean_insect_images/Spider/Spider_139.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6317</th>\n",
       "      <td>Spider</td>\n",
       "      <td>../clean_insect_images/Spider/Spider_589.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6318 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                     file_path\n",
       "0        Ant        ../clean_insect_images/Ant/Ant_472.jpg\n",
       "1        Ant         ../clean_insect_images/Ant/Ant_13.jpg\n",
       "2        Ant        ../clean_insect_images/Ant/Ant_719.jpg\n",
       "3        Ant        ../clean_insect_images/Ant/Ant_378.jpg\n",
       "4        Ant        ../clean_insect_images/Ant/Ant_641.jpg\n",
       "...      ...                                           ...\n",
       "6313  Spider  ../clean_insect_images/Spider/Spider_376.jpg\n",
       "6314  Spider  ../clean_insect_images/Spider/Spider_400.jpg\n",
       "6315  Spider  ../clean_insect_images/Spider/Spider_558.jpg\n",
       "6316  Spider  ../clean_insect_images/Spider/Spider_139.jpg\n",
       "6317  Spider  ../clean_insect_images/Spider/Spider_589.jpg\n",
       "\n",
       "[6318 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.DataFrame({'label': clean_ds['label'], 'file_path': clean_ds['file_path']})\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2540aebc-53b4-4d86-953e-6955d21ee66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ant', 'Bee', 'Butterfly', 'Dragonfly', 'Fly', 'Grasshopper', 'Ladybug',\n",
       "       'Spider'],\n",
       "      dtype='object', name='label')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c0f735a-8889-4946-b83b-e97c917d25f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['../clean_insect_images/Ant/Ant_547.jpg',\n",
       "       '../clean_insect_images/Ant/Ant_163.jpg',\n",
       "       '../clean_insect_images/Ant/Ant_524.jpg',\n",
       "       '../clean_insect_images/Ant/Ant_8.jpg',\n",
       "       '../clean_insect_images/Ant/Ant_139.jpg',\n",
       "       '../clean_insect_images/Bee/Bee_866.jpg',\n",
       "       '../clean_insect_images/Bee/Bee_858.jpg',\n",
       "       '../clean_insect_images/Bee/Bee_109.jpg',\n",
       "       '../clean_insect_images/Bee/Bee_208.jpg',\n",
       "       '../clean_insect_images/Bee/Bee_991.jpg',\n",
       "       '../clean_insect_images/Butterfly/Butterfly_48.jpg',\n",
       "       '../clean_insect_images/Butterfly/Butterfly_118.jpg',\n",
       "       '../clean_insect_images/Butterfly/Butterfly_688.jpg',\n",
       "       '../clean_insect_images/Butterfly/Butterfly_723.jpg',\n",
       "       '../clean_insect_images/Butterfly/Butterfly_273.jpg',\n",
       "       '../clean_insect_images/Dragonfly/Dragonfly_489.jpg',\n",
       "       '../clean_insect_images/Dragonfly/Dragonfly_174.jpg',\n",
       "       '../clean_insect_images/Dragonfly/Dragonfly_313.jpg',\n",
       "       '../clean_insect_images/Dragonfly/Dragonfly_363.jpg',\n",
       "       '../clean_insect_images/Dragonfly/Dragonfly_154.jpg',\n",
       "       '../clean_insect_images/Fly/Fly_441.jpg',\n",
       "       '../clean_insect_images/Fly/Fly_56.jpg',\n",
       "       '../clean_insect_images/Fly/Fly_268.png',\n",
       "       '../clean_insect_images/Fly/Fly_363.jpg',\n",
       "       '../clean_insect_images/Fly/Fly_654.jpg',\n",
       "       '../clean_insect_images/Grasshopper/Grasshopper_384.jpg',\n",
       "       '../clean_insect_images/Grasshopper/Grasshopper_473.jpg',\n",
       "       '../clean_insect_images/Grasshopper/Grasshopper_92.jpg',\n",
       "       '../clean_insect_images/Grasshopper/Grasshopper_82.jpg',\n",
       "       '../clean_insect_images/Grasshopper/Grasshopper_606.jpg',\n",
       "       '../clean_insect_images/Ladybug/Ladybug_582.png',\n",
       "       '../clean_insect_images/Ladybug/Ladybug_552.jpg',\n",
       "       '../clean_insect_images/Ladybug/Ladybug_210.jpg',\n",
       "       '../clean_insect_images/Ladybug/Ladybug_56.jpg',\n",
       "       '../clean_insect_images/Ladybug/Ladybug_485.jpg',\n",
       "       '../clean_insect_images/Spider/Spider_45.jpg',\n",
       "       '../clean_insect_images/Spider/Spider_226.jpg',\n",
       "       '../clean_insect_images/Spider/Spider_279.jpg',\n",
       "       '../clean_insect_images/Spider/Spider_619.jpg',\n",
       "       '../clean_insect_images/Spider/Spider_337.jpg'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stratefied random sample 50 images from each category\n",
    "\n",
    "random_samples = np.array([])\n",
    "for insect in clean_df.groupby('label').count().index.unique():\n",
    "    cur_sample = np.random.choice(clean_df[clean_df['label']==insect]['file_path'], 50)\n",
    "    random_samples = np.concatenate((samples,cur_sample), axis=0)\n",
    "\n",
    "val_set = list(random_samples)\n",
    "with open('../, 'w') as file:\n",
    "    file.write('\\n'.join(my_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae511ba6-39a4-4d21-819f-9df5af362cd5",
   "metadata": {},
   "source": [
    "### iNaturalist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1525646-547f-4821-a6e6-a974892350c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ant</th>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bee</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beetle</th>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Butterfly</th>\n",
       "      <td>4869</td>\n",
       "      <td>4869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fly</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grasshopper</th>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ladybug</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spider</th>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wasp</th>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             messages  species\n",
       "clean_label                   \n",
       "Ant               181      181\n",
       "Bee               300      300\n",
       "Beetle           1770     1770\n",
       "Butterfly        4869     4869\n",
       "Fly               300      300\n",
       "Grasshopper       398      398\n",
       "Ladybug           300      300\n",
       "Spider            600      600\n",
       "Wasp              175      175"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iNat36 = load_dataset(\"sxj1215/inaturalist\") #36k rows\n",
    "iNat36['train']['messages'][0]\n",
    "iNat36_df = pd.DataFrame({'messages': iNat36['train']['messages']})\n",
    "def get_iNat_label(messages):\n",
    "    return messages[1]['content']\n",
    "iNat36_df['species'] = iNat36_df['messages'].apply(get_iNat_label)\n",
    "#list(iNat36_df.groupby('species').count().index)\n",
    "def map_inat_to_clean_label(label):\n",
    "    if label in iNat_to_clean_map:\n",
    "        return iNat_to_clean_map[label]\n",
    "    else:\n",
    "        return None\n",
    "iNat36_df['clean_label'] = iNat36_df['species'].apply(map_inat_to_clean_label)\n",
    "grouped_counts = iNat36_df.groupby('clean_label').count()\n",
    "grouped_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b0304-cef7-4efe-b726-35d43c0d3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216ac976-41f0-4f6d-a1e3-36c51387ceee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iNat36_df.groupby('species').count().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cade00f1-eea5-4a24-a327-a22d73e98880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e3b6b6bafa4a15982aabb1b3af5239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1a6c70a76c491a87505cc0acf98f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00015.parquet:   0%|          | 0.00/477M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1edd786725b446f82f2c6aa134c3507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00001-of-00015.parquet:   0%|          | 0.00/473M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c815b671c69043fc9507e87a23fd6021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00002-of-00015.parquet:   0%|          | 0.00/480M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matildagaddi/miniforge3/lib/python3.12/site-packages/huggingface_hub/file_download.py:801: UserWarning: Not enough free disk space to download the file. The expected file size is: 477.24 MB. The target location /Users/matildagaddi/.cache/huggingface/hub/datasets--zguo0525--inat_2021/blobs only has 368.78 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36bab375279492eac3d95fd8f55821a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00003-of-00015.parquet:   0%|          | 0.00/477M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Data processing error: CAS service error : IO Error: No space left on device (os error 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m iNat100 \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mzguo0525/inat_2021\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m#100k rows\u001b[39;00m\n\u001b[1;32m      2\u001b[0m iNat100\u001b[39m#['train']['messages'][0]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# iNat100_df = pd.DataFrame({'messages': iNat100['train']['messages']})\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# def get_iNat_label(messages):\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#     return messages[1]['content']\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m# iNat100_df['clean_label'] = iNat100_df['species'].apply(map_inat_to_clean_label)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# iNat100_df.groupby('clean_label').count()\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/datasets/load.py:1417\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1414\u001b[0m     \u001b[39mreturn\u001b[39;00m builder_instance\u001b[39m.\u001b[39mas_streaming_dataset(split\u001b[39m=\u001b[39msplit)\n\u001b[1;32m   1416\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 1417\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[1;32m   1418\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1419\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1420\u001b[0m     verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m   1421\u001b[0m     num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m   1422\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   1423\u001b[0m )\n\u001b[1;32m   1425\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[1;32m   1427\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[1;32m   1428\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/datasets/builder.py:897\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    896\u001b[0m     prepare_split_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_proc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_proc\n\u001b[0;32m--> 897\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m    898\u001b[0m     dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[1;32m    899\u001b[0m     verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m    900\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs,\n\u001b[1;32m    901\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs,\n\u001b[1;32m    902\u001b[0m )\n\u001b[1;32m    903\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/datasets/builder.py:951\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m split_dict \u001b[39m=\u001b[39m SplitDict(dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_name)\n\u001b[1;32m    950\u001b[0m split_generators_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m--> 951\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_split_generators(dl_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msplit_generators_kwargs)\n\u001b[1;32m    953\u001b[0m \u001b[39m# Checksums verification\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[39mif\u001b[39;00m verification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS \u001b[39mand\u001b[39;00m dl_manager\u001b[39m.\u001b[39mrecord_checksums:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/datasets/packaged_modules/parquet/parquet.py:110\u001b[0m, in \u001b[0;36mParquet._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAt least one data file must be specified, but got data_files=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdata_files\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m dl_manager\u001b[39m.\u001b[39mdownload_config\u001b[39m.\u001b[39mextract_on_the_fly \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m data_files \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39;49mdownload_and_extract(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdata_files)\n\u001b[1;32m    111\u001b[0m splits \u001b[39m=\u001b[39m []\n\u001b[1;32m    112\u001b[0m \u001b[39mfor\u001b[39;00m split_name, files \u001b[39min\u001b[39;00m data_files\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/datasets/download/download_manager.py:326\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mdownload_and_extract\u001b[39m(\u001b[39mself\u001b[39m, url_or_urls):\n\u001b[1;32m    311\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Download and extract given `url_or_urls`.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \n\u001b[1;32m    313\u001b[0m \u001b[39m    Is roughly equivalent to:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39m        extracted_path(s): `str`, extracted paths of given URL(s).\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload(url_or_urls))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/datasets/download/download_manager.py:159\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    157\u001b[0m start_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m    158\u001b[0m \u001b[39mwith\u001b[39;00m stack_multiprocessing_download_progress_bars():\n\u001b[0;32m--> 159\u001b[0m     downloaded_path_or_paths \u001b[39m=\u001b[39m map_nested(\n\u001b[1;32m    160\u001b[0m         download_func,\n\u001b[1;32m    161\u001b[0m         url_or_urls,\n\u001b[1;32m    162\u001b[0m         map_tuple\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    163\u001b[0m         num_proc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mnum_proc,\n\u001b[1;32m    164\u001b[0m         desc\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDownloading data files\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    165\u001b[0m         batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    166\u001b[0m         batch_size\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m duration \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m    169\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading took \u001b[39m\u001b[39m{\u001b[39;00mduration\u001b[39m.\u001b[39mtotal_seconds()\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39m60\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m min\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/datasets/utils/py_utils.py:504\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    501\u001b[0m     num_proc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    502\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(v, types) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(v) \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(iterable) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m iterable):\n\u001b[1;32m    503\u001b[0m     mapped \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 504\u001b[0m         map_nested(\n\u001b[1;32m    505\u001b[0m             function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m    506\u001b[0m             data_struct\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m    507\u001b[0m             num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m    508\u001b[0m             parallel_min_length\u001b[39m=\u001b[39;49mparallel_min_length,\n\u001b[1;32m    509\u001b[0m             batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m    510\u001b[0m             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    511\u001b[0m             types\u001b[39m=\u001b[39;49mtypes,\n\u001b[1;32m    512\u001b[0m         )\n\u001b[1;32m    513\u001b[0m         \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m    514\u001b[0m     ]\n\u001b[1;32m    515\u001b[0m \u001b[39melif\u001b[39;00m num_proc \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(iterable) \u001b[39m<\u001b[39m parallel_min_length:\n\u001b[1;32m    516\u001b[0m     \u001b[39mif\u001b[39;00m batched:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/datasets/utils/py_utils.py:521\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    518\u001b[0m         batch_size \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mlen\u001b[39m(iterable) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m num_proc \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(iterable) \u001b[39m%\u001b[39m num_proc \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[1;32m    519\u001b[0m     iterable \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[1;32m    520\u001b[0m mapped \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 521\u001b[0m     _single_map_nested((function, obj, batched, batch_size, types, \u001b[39mNone\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m))\n\u001b[1;32m    522\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m hf_tqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[1;32m    523\u001b[0m ]\n\u001b[1;32m    524\u001b[0m \u001b[39mif\u001b[39;00m batched:\n\u001b[1;32m    525\u001b[0m     mapped \u001b[39m=\u001b[39m [mapped_item \u001b[39mfor\u001b[39;00m mapped_batch \u001b[39min\u001b[39;00m mapped \u001b[39mfor\u001b[39;00m mapped_item \u001b[39min\u001b[39;00m mapped_batch]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/datasets/utils/py_utils.py:389\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[39mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    384\u001b[0m     batched\n\u001b[1;32m    385\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m)\n\u001b[1;32m    386\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, types)\n\u001b[1;32m    387\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(v, (\u001b[39mdict\u001b[39m, types)) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m data_struct)\n\u001b[1;32m    388\u001b[0m ):\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mreturn\u001b[39;00m [mapped_item \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[39mfor\u001b[39;00m mapped_item \u001b[39min\u001b[39;00m function(batch)]\n\u001b[1;32m    391\u001b[0m \u001b[39m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m logging\u001b[39m.\u001b[39mget_verbosity() \u001b[39m<\u001b[39m logging\u001b[39m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/datasets/download/download_manager.py:220\u001b[0m, in \u001b[0;36mDownloadManager._download_batched\u001b[0;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[39mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    207\u001b[0m         download_func,\n\u001b[1;32m    208\u001b[0m         url_or_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m         tqdm_class\u001b[39m=\u001b[39mtqdm,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    218\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m--> 220\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_single(url_or_filename, download_config\u001b[39m=\u001b[39;49mdownload_config)\n\u001b[1;32m    221\u001b[0m         \u001b[39mfor\u001b[39;00m url_or_filename \u001b[39min\u001b[39;00m url_or_filenames\n\u001b[1;32m    222\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/datasets/download/download_manager.py:229\u001b[0m, in \u001b[0;36mDownloadManager._download_single\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[1;32m    227\u001b[0m     \u001b[39m# append the relative path to the base_path\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     url_or_filename \u001b[39m=\u001b[39m url_or_path_join(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_path, url_or_filename)\n\u001b[0;32m--> 229\u001b[0m out \u001b[39m=\u001b[39m cached_path(url_or_filename, download_config\u001b[39m=\u001b[39;49mdownload_config)\n\u001b[1;32m    230\u001b[0m out \u001b[39m=\u001b[39m tracked_str(out)\n\u001b[1;32m    231\u001b[0m out\u001b[39m.\u001b[39mset_origin(url_or_filename)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/datasets/utils/file_utils.py:188\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m resolved_path \u001b[39m=\u001b[39m huggingface_hub\u001b[39m.\u001b[39mHfFileSystem(\n\u001b[1;32m    179\u001b[0m     endpoint\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mHF_ENDPOINT, token\u001b[39m=\u001b[39mdownload_config\u001b[39m.\u001b[39mtoken\n\u001b[1;32m    180\u001b[0m )\u001b[39m.\u001b[39mresolve_path(url_or_filename)\n\u001b[1;32m    181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     output_path \u001b[39m=\u001b[39m huggingface_hub\u001b[39m.\u001b[39;49mHfApi(\n\u001b[1;32m    183\u001b[0m         endpoint\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mHF_ENDPOINT,\n\u001b[1;32m    184\u001b[0m         token\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mtoken,\n\u001b[1;32m    185\u001b[0m         library_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdatasets\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    186\u001b[0m         library_version\u001b[39m=\u001b[39;49m__version__,\n\u001b[1;32m    187\u001b[0m         user_agent\u001b[39m=\u001b[39;49mget_datasets_user_agent(download_config\u001b[39m.\u001b[39;49muser_agent),\n\u001b[0;32m--> 188\u001b[0m     )\u001b[39m.\u001b[39;49mhf_hub_download(\n\u001b[1;32m    189\u001b[0m         repo_id\u001b[39m=\u001b[39;49mresolved_path\u001b[39m.\u001b[39;49mrepo_id,\n\u001b[1;32m    190\u001b[0m         repo_type\u001b[39m=\u001b[39;49mresolved_path\u001b[39m.\u001b[39;49mrepo_type,\n\u001b[1;32m    191\u001b[0m         revision\u001b[39m=\u001b[39;49mresolved_path\u001b[39m.\u001b[39;49mrevision,\n\u001b[1;32m    192\u001b[0m         filename\u001b[39m=\u001b[39;49mresolved_path\u001b[39m.\u001b[39;49mpath_in_repo,\n\u001b[1;32m    193\u001b[0m         force_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mforce_download,\n\u001b[1;32m    194\u001b[0m         proxies\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    195\u001b[0m     )\n\u001b[1;32m    196\u001b[0m \u001b[39mexcept\u001b[39;00m (\n\u001b[1;32m    197\u001b[0m     huggingface_hub\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mRepositoryNotFoundError,\n\u001b[1;32m    198\u001b[0m     huggingface_hub\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mEntryNotFoundError,\n\u001b[1;32m    199\u001b[0m     huggingface_hub\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mRevisionNotFoundError,\n\u001b[1;32m    200\u001b[0m     huggingface_hub\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mGatedRepoError,\n\u001b[1;32m    201\u001b[0m ) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5539\u001b[0m, in \u001b[0;36mHfApi.hf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, proxies, etag_timeout, token, local_files_only, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   5535\u001b[0m \u001b[39mif\u001b[39;00m token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5536\u001b[0m     \u001b[39m# Cannot do `token = token or self.token` as token can be `False`.\u001b[39;00m\n\u001b[1;32m   5537\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken\n\u001b[0;32m-> 5539\u001b[0m \u001b[39mreturn\u001b[39;00m hf_hub_download(\n\u001b[1;32m   5540\u001b[0m     repo_id\u001b[39m=\u001b[39;49mrepo_id,\n\u001b[1;32m   5541\u001b[0m     filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[1;32m   5542\u001b[0m     subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   5543\u001b[0m     repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m   5544\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   5545\u001b[0m     endpoint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendpoint,\n\u001b[1;32m   5546\u001b[0m     library_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlibrary_name,\n\u001b[1;32m   5547\u001b[0m     library_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlibrary_version,\n\u001b[1;32m   5548\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   5549\u001b[0m     local_dir\u001b[39m=\u001b[39;49mlocal_dir,\n\u001b[1;32m   5550\u001b[0m     local_dir_use_symlinks\u001b[39m=\u001b[39;49mlocal_dir_use_symlinks,\n\u001b[1;32m   5551\u001b[0m     user_agent\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muser_agent,\n\u001b[1;32m   5552\u001b[0m     force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   5553\u001b[0m     force_filename\u001b[39m=\u001b[39;49mforce_filename,\n\u001b[1;32m   5554\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   5555\u001b[0m     etag_timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[1;32m   5556\u001b[0m     resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   5557\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   5558\u001b[0m     headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m   5559\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   5560\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1010\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[39mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    991\u001b[0m         \u001b[39m# Destination\u001b[39;00m\n\u001b[1;32m    992\u001b[0m         local_dir\u001b[39m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         local_files_only\u001b[39m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1010\u001b[0m     \u001b[39mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[1;32m   1011\u001b[0m         \u001b[39m# Destination\u001b[39;49;00m\n\u001b[1;32m   1012\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1013\u001b[0m         \u001b[39m# File info\u001b[39;49;00m\n\u001b[1;32m   1014\u001b[0m         repo_id\u001b[39m=\u001b[39;49mrepo_id,\n\u001b[1;32m   1015\u001b[0m         filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[1;32m   1016\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m   1017\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1018\u001b[0m         \u001b[39m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1019\u001b[0m         endpoint\u001b[39m=\u001b[39;49mendpoint,\n\u001b[1;32m   1020\u001b[0m         etag_timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[1;32m   1021\u001b[0m         headers\u001b[39m=\u001b[39;49mhf_headers,\n\u001b[1;32m   1022\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1023\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1024\u001b[0m         \u001b[39m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1025\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1026\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   1027\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1171\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[39m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[39mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1171\u001b[0m     _download_to_tmp_and_move(\n\u001b[1;32m   1172\u001b[0m         incomplete_path\u001b[39m=\u001b[39;49mPath(blob_path \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.incomplete\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1173\u001b[0m         destination_path\u001b[39m=\u001b[39;49mPath(blob_path),\n\u001b[1;32m   1174\u001b[0m         url_to_download\u001b[39m=\u001b[39;49murl_to_download,\n\u001b[1;32m   1175\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1176\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m   1177\u001b[0m         expected_size\u001b[39m=\u001b[39;49mexpected_size,\n\u001b[1;32m   1178\u001b[0m         filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[1;32m   1179\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   1180\u001b[0m         etag\u001b[39m=\u001b[39;49metag,\n\u001b[1;32m   1181\u001b[0m         xet_file_data\u001b[39m=\u001b[39;49mxet_file_data,\n\u001b[1;32m   1182\u001b[0m     )\n\u001b[1;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1184\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1723\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[39mif\u001b[39;00m xet_file_data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m is_xet_available():\n\u001b[1;32m   1722\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1723\u001b[0m     xet_get(\n\u001b[1;32m   1724\u001b[0m         incomplete_path\u001b[39m=\u001b[39;49mincomplete_path,\n\u001b[1;32m   1725\u001b[0m         xet_file_data\u001b[39m=\u001b[39;49mxet_file_data,\n\u001b[1;32m   1726\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m   1727\u001b[0m         expected_size\u001b[39m=\u001b[39;49mexpected_size,\n\u001b[1;32m   1728\u001b[0m         displayed_filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[1;32m   1729\u001b[0m     )\n\u001b[1;32m   1730\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     \u001b[39mif\u001b[39;00m xet_file_data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m constants\u001b[39m.\u001b[39mHF_HUB_DISABLE_XET:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/file_download.py:629\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mprogress_updater\u001b[39m(progress_bytes: \u001b[39mfloat\u001b[39m):\n\u001b[1;32m    627\u001b[0m     progress\u001b[39m.\u001b[39mupdate(progress_bytes)\n\u001b[0;32m--> 629\u001b[0m download_files(\n\u001b[1;32m    630\u001b[0m     xet_download_info,\n\u001b[1;32m    631\u001b[0m     endpoint\u001b[39m=\u001b[39;49mconnection_info\u001b[39m.\u001b[39;49mendpoint,\n\u001b[1;32m    632\u001b[0m     token_info\u001b[39m=\u001b[39;49m(connection_info\u001b[39m.\u001b[39;49maccess_token, connection_info\u001b[39m.\u001b[39;49mexpiration_unix_epoch),\n\u001b[1;32m    633\u001b[0m     token_refresher\u001b[39m=\u001b[39;49mtoken_refresher,\n\u001b[1;32m    634\u001b[0m     progress_updater\u001b[39m=\u001b[39;49m[progress_updater],\n\u001b[1;32m    635\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Data processing error: CAS service error : IO Error: No space left on device (os error 28)"
     ]
    }
   ],
   "source": [
    "# iNat100 = load_dataset(\"zguo0525/inat_2021\") #100k rows\n",
    "# iNat100#['train']['messages'][0]\n",
    "# iNat100_df = pd.DataFrame({'messages': iNat100['train']['messages']})\n",
    "# def get_iNat_label(messages):\n",
    "#     return messages[1]['content']\n",
    "# iNat100_df['species'] = iNat100_df['messages'].apply(get_iNat_label)\n",
    "# #list(iNat36_df.groupby('species').count().index)\n",
    "# len(iNat36_df.groupby('species').count().index)\n",
    "# def map_inat_to_clean_label(label):\n",
    "#     if label in iNat_to_clean_map:\n",
    "#         return iNat_to_clean_map[label]\n",
    "#     else:\n",
    "#         return None\n",
    "# iNat100_df['clean_label'] = iNat100_df['species'].apply(map_inat_to_clean_label)\n",
    "# iNat100_df.groupby('clean_label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89158b4-6b47-4ca4-ad16-e6a76a69bbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#would need to check overlap with following\n",
    "#juppy44/inat2021-train-mini-test #500k #unsure image format (no preview)\n",
    "#MVRL/iNat-2021-train #500k \n",
    "#MVRL/iNat-2021-train #2.69mil #weird and inconsistent image formats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
