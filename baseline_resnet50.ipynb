{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec46e862",
   "metadata": {},
   "source": [
    "## Run Baseline ResNet-50 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0461c547",
   "metadata": {},
   "source": [
    "TASK: Detect Insect Type \\\n",
    "Dataset: iNaturalist \\\n",
    "Model: Resnet-50 (pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68b3b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install datasets\n",
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0499076d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/resnet/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3544062d",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "860b700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/sxj1215/inaturalist\n",
    "dataset = load_dataset(\"sxj1215/inaturalist\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5a0564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Matilda's label mapping (take from utils/label_mapping.py in the future)\n",
    "iNat_to_clean_map = {\n",
    "    # Ants\n",
    "    \"Camponotus planatus\": \"Ant\",\n",
    "    \n",
    "    # Bees\n",
    "    \"Agapostemon virescens\": \"Bee\",\n",
    "\n",
    "    # Beetles\n",
    "    \"Alaus lusciosus\": \"Beetle\",\n",
    "    \"Buprestis aurulenta\": \"Beetle\",\n",
    "    \"Chrysolina americana\": \"Beetle\",\n",
    "    \"Cicindela hirticollis\": \"Beetle\",\n",
    "    \"Epicauta pennsylvanica\": \"Beetle\",\n",
    "    \"Polydrusus formosus\": \"Beetle\",\n",
    "    \"Trypoxylus dichotomus\": \"Beetle\",\n",
    "\n",
    "    # Butterflies\n",
    "    \"Aglais urticae\": \"Butterfly\",\n",
    "    \"Anartia amathea\": \"Butterfly\",\n",
    "    \"Cigaritis lohita\": \"Butterfly\",\n",
    "    \"Euphyes vestris\": \"Butterfly\",\n",
    "    \"Icaricia acmon\": \"Butterfly\",\n",
    "    \"Icaricia lupini\": \"Butterfly\",\n",
    "    \"Panoquina ocola\": \"Butterfly\",\n",
    "\n",
    "    # # Moths \n",
    "    # \"Agrotis segetum\": \"Butterfly\",\n",
    "    # \"Aphomia sociella\": \"Butterfly\",\n",
    "    # \"Apogeshna stenialis\": \"Butterfly\",\n",
    "    # \"Cabera pusaria\": \"Butterfly\",\n",
    "    # \"Ceratomia catalpae\": \"Butterfly\",\n",
    "    # \"Enyo lugubris\": \"Butterfly\",\n",
    "    # \"Gastrina cristaria\": \"Butterfly\",\n",
    "    # \"Gymnandrosoma punctidiscanum\": \"Butterfly\",\n",
    "    # \"Heterophleps triguttaria\": \"Butterfly\",\n",
    "    # \"Ochropleura plecta\": \"Butterfly\",\n",
    "    # \"Thaumetopoea processionea\": \"Butterfly\",\n",
    "    # \"Triphosa haesitata\": \"Butterfly\",\n",
    "\n",
    "    # Dragonflies\n",
    "    \n",
    "    # Flies\n",
    "\n",
    "    # Grasshoppers\n",
    "    \"Gomphocerippus rufus\": \"Grasshopper\",\n",
    "\n",
    "    # Ladybugs\n",
    "    \"Hippodamia variegata\": \"Ladybug\",\n",
    "\n",
    "    # Mosquito\n",
    "\n",
    "    # Spiders\n",
    "    \"Aphonopelma chalcodes\": \"Spider\",\n",
    "    \"Platycryptus undatus\": \"Spider\",\n",
    "\n",
    "    # Wasps\n",
    "    \"Chlorion aerarium\": \"Wasp\" #this wasp is blue though\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "862b7bc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "image file is truncated (122 bytes not processed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m img_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m      7\u001b[0m     original_label \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m original_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m iNat_to_clean_map:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/resnet/lib/python3.10/site-packages/datasets/arrow_dataset.py:2483\u001b[0m, in \u001b[0;36mDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2481\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(pa_subtable\u001b[38;5;241m.\u001b[39mnum_rows):\n\u001b[1;32m   2482\u001b[0m             pa_subtable_ex \u001b[38;5;241m=\u001b[39m pa_subtable\u001b[38;5;241m.\u001b[39mslice(i, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 2483\u001b[0m             formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2484\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpa_subtable_ex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2485\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2486\u001b[0m \u001b[43m                \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2487\u001b[0m \u001b[43m                \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2488\u001b[0m \u001b[43m                \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_all_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2489\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2490\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m formatted_output\n\u001b[1;32m   2491\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/resnet/lib/python3.10/site-packages/datasets/formatting/formatting.py:658\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    656\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/resnet/lib/python3.10/site-packages/datasets/formatting/formatting.py:411\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 411\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/resnet/lib/python3.10/site-packages/datasets/formatting/formatting.py:460\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    459\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[0;32m--> 460\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[0;32m/opt/anaconda3/envs/resnet/lib/python3.10/site-packages/datasets/formatting/formatting.py:224\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m row\n",
      "File \u001b[0;32m/opt/anaconda3/envs/resnet/lib/python3.10/site-packages/datasets/features/features.py:2110\u001b[0m, in \u001b[0;36mFeatures.decode_example\u001b[0;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[1;32m   2098\u001b[0m \n\u001b[1;32m   2099\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m   2111\u001b[0m         column_name: decode_nested_example(feature, value, token_per_repo_id\u001b[38;5;241m=\u001b[39mtoken_per_repo_id)\n\u001b[1;32m   2112\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   2113\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[1;32m   2114\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[1;32m   2115\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[1;32m   2116\u001b[0m         )\n\u001b[1;32m   2117\u001b[0m     }\n",
      "File \u001b[0;32m/opt/anaconda3/envs/resnet/lib/python3.10/site-packages/datasets/features/features.py:2111\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[1;32m   2098\u001b[0m \n\u001b[1;32m   2099\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m-> 2111\u001b[0m         column_name: \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2112\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   2113\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[1;32m   2114\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[1;32m   2115\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[1;32m   2116\u001b[0m         )\n\u001b[1;32m   2117\u001b[0m     }\n",
      "File \u001b[0;32m/opt/anaconda3/envs/resnet/lib/python3.10/site-packages/datasets/features/features.py:1413\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1411\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _check_non_null_non_empty_recursive(first_elmt, sub_schema):\n\u001b[1;32m   1412\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1413\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_elmt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m first_elmt:\n\u001b[1;32m   1414\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [decode_nested_example(sub_schema, o) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(obj)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/resnet/lib/python3.10/site-packages/datasets/features/features.py:1419\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;66;03m# Object with special decoding:\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode_example\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/anaconda3/envs/resnet/lib/python3.10/site-packages/datasets/features/image.py:193\u001b[0m, in \u001b[0;36mImage.decode_example\u001b[0;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(BytesIO(bytes_))\n\u001b[0;32m--> 193\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mgetexif()\u001b[38;5;241m.\u001b[39mget(PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mExifTags\u001b[38;5;241m.\u001b[39mBase\u001b[38;5;241m.\u001b[39mOrientation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImageOps\u001b[38;5;241m.\u001b[39mexif_transpose(image)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/resnet/lib/python3.10/site-packages/PIL/ImageFile.py:403\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    400\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage file is truncated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    401\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(b)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes not processed)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         )\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    405\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m    406\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n",
      "\u001b[0;31mOSError\u001b[0m: image file is truncated (122 bytes not processed)"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "rows = []\n",
    "img_id = 0\n",
    "\n",
    "for row in dataset:\n",
    "    original_label = row[\"messages\"][1][\"content\"]\n",
    "\n",
    "    if original_label not in iNat_to_clean_map:\n",
    "        continue  # skip unmapped species (?), should there be a different OTHER class\n",
    "\n",
    "    clean_label = iNat_to_clean_map.get(original_label, original_label)\n",
    "\n",
    "    image_path = f\"images/{img_id}.jpg\"\n",
    "    row[\"images\"][0].save(image_path)\n",
    "\n",
    "    rows.append(f\"{image_path},{clean_label}\")\n",
    "    img_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d2c4a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"labels.csv\", \"w\") as f:\n",
    "    f.write(\"image,label\\n\")\n",
    "    f.write(\"\\n\".join(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d4b12",
   "metadata": {},
   "source": [
    "Custom Dataset Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b3e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses RandomResizedCrop, RandomHorizontalFlip to help model generalize\n",
    "# applies standard ImageNet normalization\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66941fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom PyTorch Dataset class to load images and convert labels to integers\n",
    "\n",
    "class JPGDataset(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "        self.data = data_df  # now accepts a df directly\n",
    "        self.transform = transform\n",
    "\n",
    "        # map label strings to integers\n",
    "        self.classes = sorted(self.data.label.unique())\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image = Image.open(row.image).convert(\"RGB\")\n",
    "        label = self.class_to_idx[row.label]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3fab8",
   "metadata": {},
   "source": [
    "Model Architecture/Training (random sample, cross-val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b51247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00e307ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69bf966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Epoch 1: train=0.754, val=0.944\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "df = pd.read_csv(\"labels.csv\")\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_accuracies = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "    print(f\"\\n--- Starting Fold {fold + 1}/5 ---\")\n",
    "    \n",
    "    # create df for eacg fold\n",
    "    train_df = df.iloc[train_idx]\n",
    "    val_df = df.iloc[val_idx]\n",
    "    \n",
    "    # initialize datasets and loaders\n",
    "    train_dataset = JPGDataset(train_df, transform=train_transforms)\n",
    "    val_dataset   = JPGDataset(val_df, transform=val_transforms)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    num_classes = len(train_dataset.classes)\n",
    "\n",
    "    # re-initialize the model for every fold to prevent weight leakage\n",
    "    model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # freeze backbone weights and unfreeze the new head\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)\n",
    "\n",
    "    # train for 2 epochs per fold\n",
    "    for epoch in range(2):\n",
    "        train_acc = train_one_epoch(model, train_loader)\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        print(f\"Epoch {epoch+1}: train={train_acc:.3f}, val={val_acc:.3f}\")\n",
    "    \n",
    "    fold_accuracies.append(val_acc)\n",
    "\n",
    "print(f\"\\nAverage 5-Fold Accuracy: {np.mean(all_fold_results):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d1f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final weights and class names\n",
    "torch.save({\n",
    "    \"model\": model.state_dict(),\n",
    "    \"classes\": train_dataset.classes\n",
    "}, \"resnet50_insects_cv.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b56329",
   "metadata": {},
   "source": [
    "Model Architecture/Training (random sample, no cross-val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b89a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labels.csv\")\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df.label,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "val_df.to_csv(\"val.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff2b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = JPGDataset(\"train.csv\", transform=train_transforms)\n",
    "val_dataset   = JPGDataset(\"val.csv\", transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02227c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# load the pre-trained resnet50 model\n",
    "model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "# replace the final layer with new layer with the number of insect classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0239dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the backbone weights of the ResNet are frozen\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# only the new final layer will be updated during the training (fine-tuning step 1)\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64816571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model trained using Adam optimizer and CrossEntropyLoss\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.fc.parameters(),\n",
    "    lr=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffb2954b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train=0.767, val=0.927\n",
      "Epoch 2: train=0.891, val=0.956\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc = train_one_epoch(model, train_loader)\n",
    "    val_acc = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: train={train_acc:.3f}, val={val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df43e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final weights and class names\n",
    "\n",
    "torch.save({\n",
    "    \"model\": model.state_dict(),\n",
    "    \"classes\": train_dataset.classes\n",
    "}, \"resnet50_insects.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4565123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
