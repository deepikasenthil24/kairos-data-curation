{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27963141",
   "metadata": {},
   "source": [
    "### Extract Embeddings\n",
    "\n",
    "Based on https://github.com/rom1504/clip-retrieval\n",
    "\n",
    "First, pip install clip-retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd7751b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from datasets import Image\n",
    "import pandas as pd\n",
    "from utils.label_mappings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb8f4a8-bac4-49f0-9376-8f790ef30eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ea5e9",
   "metadata": {},
   "source": [
    "#### iNaturalist Embeddings\n",
    "Need to get embeddings for all images in iNat dataset (3.3GB) for Kairos to curate the insects from the rest (noisy). 36355 rows/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1264e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "#IMG_DIR = \"inat_images\" #should probably just load the huggingface dataset if possible\n",
    "iNat36 = load_dataset(\"sxj1215/inaturalist\", split='train') #36k rows #3.3 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a6d886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1238 images on cuda...\n"
     ]
    }
   ],
   "source": [
    "# Get image paths\n",
    "# valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.webp')\n",
    "# image_paths = sorted([os.path.join(IMG_DIR, f) for f in os.listdir(IMG_DIR) \n",
    "#                       if f.lower().endswith(valid_exts)])\n",
    "\n",
    "# print(f\"Processing {len(image_paths)} images on {device}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db7273ed-5bdb-4cf0-87d2-fa2365cfe121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to use all images for embeddings\n",
    "# Need to generate unique IDs for metadata/filenames \n",
    "iNat36_label_df = pd.DataFrame({'messages': iNat36['messages']})\n",
    "def get_iNat_label(messages):\n",
    "    return messages[1]['content']\n",
    "iNat36_label_df['species'] = iNat36_label_df['messages'].apply(get_iNat_label)\n",
    "#list(iNat36_df.groupby('species').count().index)\n",
    "def map_inat_to_clean_label(label):\n",
    "    if label in iNat_to_clean_map:\n",
    "        return iNat_to_clean_map[label]\n",
    "    else:\n",
    "        return 'noise'\n",
    "iNat36_label_df['clean_label'] = iNat36_label_df['species'].apply(map_inat_to_clean_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0e21da4-e8e3-4c86-980e-2a946d63ea95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    noise\n",
       "1    noise\n",
       "2    noise\n",
       "3    noise\n",
       "4    noise\n",
       "5    noise\n",
       "6    noise\n",
       "7    noise\n",
       "8    noise\n",
       "9    noise\n",
       "Name: clean_label, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iNat36_label_df.iloc[:10].get('clean_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f21d054c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36355/36355 [09:56<00:00, 60.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 36354 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = \"inat_embs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "# Extraction loop\n",
    "inat_embeddings = []\n",
    "inat_metadata = []\n",
    "\n",
    "for idx in tqdm(range(len(iNat36))):\n",
    "    try:\n",
    "        row = iNat36[idx]\n",
    "        img = row[\"images\"][0]\n",
    "        img = preprocess(img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            feats = model.encode_image(img)\n",
    "            feats /= feats.norm(dim=-1, keepdim=True)\n",
    "        inat_embeddings.append(feats.cpu().numpy())\n",
    "        inat_metadata.append(iNat36_label_df.iloc[idx][\"clean_label\"])\n",
    "    except Exception as e:\n",
    "        inat_embeddings.append('skip') #need to add these so indexes line up later\n",
    "        inat_metadata.append('skip')\n",
    "        continue\n",
    "\n",
    "print(f\"Successfully processed {len(inat_embeddings)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f99bb5df-a284-4f3c-aa21-78dec4e0d548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36354"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inat_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ae6108f-5306-431e-8d82-61bcbab80fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36354"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inat_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb9e2d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Saved (36354, 512) matrix to inat_embs/embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "if inat_embeddings:\n",
    "    emb_matrix = np.vstack(inat_embeddings)\n",
    "    \n",
    "    np.save(os.path.join(OUT_DIR, \"embeddings.npy\"), emb_matrix)\n",
    "    \n",
    "    with open(os.path.join(OUT_DIR, \"metadata.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(inat_metadata))\n",
    "        \n",
    "    print(f\"Success! Saved {emb_matrix.shape} matrix to {OUT_DIR}/embeddings.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b72a60-7614-4905-ad6d-61d0f9e05b1e",
   "metadata": {},
   "source": [
    "#### Kaggle Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cce590df-ac02-44a8-ab01-6f5c5bfb0c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 46.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from sample_clean_data import sampled_clean_data \n",
    "# Settings\n",
    "IMG_DIR = \"clean_insect_images\"\n",
    "OUT_DIR = \"clean_embs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Extraction loop\n",
    "clean_embeddings = []\n",
    "clean_metadata = []\n",
    "\n",
    "for path in tqdm(sampled_clean_data): # only look at the samples clean images\n",
    "    try:\n",
    "        image = preprocess(Image.open(path)).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = model.encode_image(image)\n",
    "            features /= features.norm(dim=-1, keepdim=True)    # normalize for cosine similarity\n",
    "            \n",
    "        clean_embeddings.append(features.cpu().numpy())\n",
    "        clean_metadata.append(path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping corrupt image {path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4449eb4-d4e6-40df-b614-85986944114c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Saved (400, 512) matrix to clean_embs/embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "if embeddings:\n",
    "    emb_matrix = np.vstack(clean_embeddings)\n",
    "    \n",
    "    np.save(os.path.join(OUT_DIR, \"embeddings.npy\"), emb_matrix)\n",
    "    \n",
    "    with open(os.path.join(OUT_DIR, \"metadata.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(clean_metadata))\n",
    "        \n",
    "    print(f\"Success! Saved {emb_matrix.shape} matrix to {OUT_DIR}/embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff52d1-91c0-4e7e-b899-ee2ac1b0ca6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
