{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27963141",
   "metadata": {},
   "source": [
    "### Extract Embeddings\n",
    "\n",
    "Based on https://github.com/rom1504/clip-retrieval\n",
    "\n",
    "First, pip install clip-retrieval\n",
    "\n",
    "`pip install git+https://github.com/openai/CLIP.git`\n",
    "\n",
    "TODO:\n",
    "- labels fed to Kairos should be species/insect type, not \"Noisy\" vs \"clean\"\n",
    "- Need to save list of indexes of noisy images in iNat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd7751b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "import pandas as pd\n",
    "from utils.label_mappings import *\n",
    "\n",
    "OUT_DIR = 'data/embs'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb8f4a8-bac4-49f0-9376-8f790ef30eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ea5e9",
   "metadata": {},
   "source": [
    "#### iNaturalist Embeddings\n",
    "Need to get embeddings for all images in iNat dataset (3.3GB) for Kairos to curate the insects from the rest (noisy). 36355 rows/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1264e866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages', 'images', 'id'],\n",
       "    num_rows: 36355\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load iNat data\n",
    "iNat36 = load_dataset(\"sxj1215/inaturalist\", split='train') #36k rows #3.3 GB\n",
    "ids = list(range(len(iNat36)))\n",
    "iNat36 = iNat36.add_column(\"id\", ids) #not idempotent\n",
    "iNat36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7273ed-5bdb-4cf0-87d2-fa2365cfe121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['noise' 'Ant' 'Ladybug' 'Butterfly' 'Spider' 'Beetle' 'Grasshopper' 'Bee']\n"
     ]
    }
   ],
   "source": [
    "iNat36_label_df = pd.DataFrame({'messages': iNat36['messages'], 'id': iNat36['id']})\n",
    "\n",
    "def get_iNat_label(messages):\n",
    "    return messages[1]['content']\n",
    "    \n",
    "iNat36_label_df['species'] = iNat36_label_df['messages'].apply(get_iNat_label)\n",
    "\n",
    "def map_inat_to_clean_label(label):\n",
    "    if label in iNat_to_clean_map:\n",
    "        return iNat_to_clean_map[label]\n",
    "    else:\n",
    "        return 'noise'\n",
    "        #add index to noisy index list here?\n",
    "        \n",
    "iNat36_label_df['clean_label'] = iNat36_label_df['species'].apply(map_inat_to_clean_label)\n",
    "print(iNat36_label_df['clean_label'].unique()) # check that we are using the correct classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe30bfb-2218-43e3-98fd-151303975624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save noisy indexes for Kairos\n",
    "noisy_idxs = iNat36_label_df[iNat36_label_df['clean_label'] == 'noise'].index\n",
    "np.save(os.path.join(OUT_DIR, f\"inat_noisy_indexes.npy\"), noisy_idxs)\n",
    "clean_idxs = iNat36_label_df[iNat36_label_df['clean_label'] != 'noise'].index\n",
    "np.save(os.path.join(OUT_DIR, f\"inat_clean_indexes.npy\"), clean_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f21d054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inat_embs(inat_split_ds, file_prefix, out_dir):\n",
    "    '''\n",
    "    inat_split_ds is a split (train, test) of the iNat dataset\n",
    "    \n",
    "    file_prefix is a string to clearly label files and distinguish different groups of embeddings\n",
    "    such as 'train_inat' or 'test_inat' \n",
    "\n",
    "    out_dir is the directory the data will be saved to\n",
    "    '''\n",
    "    embs = []\n",
    "    labels = []\n",
    "    row_ids = [] # only needed if we are shuffling later\n",
    "\n",
    "    for i in tqdm(range(len(inat_split_ds))):\n",
    "        try:\n",
    "            row = inat_split_ds[i]\n",
    "            row_id = row['id']\n",
    "            img = row[\"images\"][0]\n",
    "            img = preprocess(img).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                feats = model.encode_image(img)\n",
    "                feats /= feats.norm(dim=-1, keepdim=True)\n",
    "            embs.append(feats.cpu().numpy()) \n",
    "            labels.append(iNat36_label_df.iloc[row_id][\"clean_label\"]) # can use species as label for now, but need clean_label later for resnet\n",
    "            row_ids.append(row_id)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            embs.append(np.zeros(512).reshape(1, 512)) #need to add placeholder so entries line up later\n",
    "            labels.append('noise')\n",
    "            row_ids.append(row_id)\n",
    "            continue\n",
    "\n",
    "    \n",
    "    print(f\"Successfully processed {len(embs)} examples\")\n",
    "\n",
    "    if embs:\n",
    "        emb_matrix = np.vstack(embs)\n",
    "        \\\n",
    "        np.save(os.path.join(OUT_DIR, f\"{file_prefix}_embeddings.npy\"), emb_matrix)\n",
    "        np.save(os.path.join(OUT_DIR, f\"{file_prefix}_labels.npy\"), labels)\n",
    "        \n",
    "        with open(os.path.join(OUT_DIR, f\"{file_prefix}_row_ids.txt\"), \"w\") as f:\n",
    "            f.write(str(row_ids))\n",
    "            \n",
    "        print(f\"Success! Saved {emb_matrix.shape} matrix to {OUT_DIR}\")\n",
    "\n",
    "\n",
    "    return embs, labels, row_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ed89cf-cb49-4b0f-9150-cc7735131272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 7196/36355 [01:55<07:14, 67.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image file is truncated (122 bytes not processed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36355/36355 [09:41<00:00, 62.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 36355 examples\n",
      "Success! Saved (36355, 512) matrix to data/embs\n"
     ]
    }
   ],
   "source": [
    "inat_embeddings, inat_labels, inat_row_ids = generate_inat_embs(iNat36, 'inat', OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b72a60-7614-4905-ad6d-61d0f9e05b1e",
   "metadata": {},
   "source": [
    "#### Kaggle clean embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cce590df-ac02-44a8-ab01-6f5c5bfb0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sample_clean_data import kairos_clean_data, test_clean_data # stratefied random sampled data for kairos and rest of data for resnet test\n",
    "label_pos_in_path = 2\n",
    "\n",
    "def generate_clean_embs(images_var, file_prefix, out_dir):\n",
    "    '''\n",
    "    images var is a list of filepaths and is defined in sample_clean_data.py\n",
    "    \n",
    "    file_prefix is a string to clearly label files and distinguish different groups of embeddings\n",
    "    such as 'kairos_clean' or 'test_clean' \n",
    "\n",
    "    out_dir is the directory the data will be saved to\n",
    "    '''\n",
    "    \n",
    "    embs = []\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    #i = 0\n",
    "\n",
    "    for path in tqdm(images_var): # path = data/clean_insect_images/Ant/Ant_283.jpg\n",
    "        # if i < 2:\n",
    "        #     print(path) # to verify same images are sampled for downstream reproducibility\n",
    "        #i+=1\n",
    "        try:\n",
    "            image = preprocess(Image.open(path)).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                features = model.encode_image(image)\n",
    "                features /= features.norm(dim=-1, keepdim=True)    # normalize for cosine similarity\n",
    "                \n",
    "            embs.append(features.cpu().numpy())\n",
    "            labels.append(path.split('/')[label_pos_in_path])\n",
    "            filepaths.append(path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping corrupt image {path}: {e}\")\n",
    "    \n",
    "    print(f\"Successfully processed {len(embs)} examples\")\n",
    "    print(set(labels))\n",
    "    \n",
    "    if embs:\n",
    "        emb_matrix = np.vstack(embs)\n",
    "        \n",
    "        np.save(os.path.join(OUT_DIR, f\"{file_prefix}_embeddings.npy\"), emb_matrix)\n",
    "        np.save(os.path.join(OUT_DIR, f\"{file_prefix}_labels.npy\"), labels)\n",
    "        \n",
    "        with open(os.path.join(OUT_DIR, f\"{file_prefix}_filepaths.txt\"), \"w\") as f:\n",
    "            f.write(str(filepaths))\n",
    "            \n",
    "        print(f\"Success! Saved {emb_matrix.shape} matrix to {OUT_DIR}\")\n",
    "\n",
    "\n",
    "    return embs, labels, filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4449eb4-d4e6-40df-b614-85986944114c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [00:07<00:00, 48.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 350 examples\n",
      "{'Ladybug', 'Spider', 'Butterfly', 'Bee', 'Grasshopper', 'Ant', 'Beetle'}\n",
      "Success! Saved (350, 512) matrix to data/embs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 363/5354 [00:07<01:36, 51.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping corrupt image data/clean_insect_images/Ant/.ipynb_checkpoints: [Errno 21] Is a directory: '/home/mgaddi/kairos-data-curation/data/clean_insect_images/Ant/.ipynb_checkpoints'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 562/5354 [00:12<01:39, 48.12it/s]/opt/conda/lib/python3.11/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "100%|██████████| 5354/5354 [02:00<00:00, 44.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 5353 examples\n",
      "{'Ladybug', 'Spider', 'Butterfly', 'Bee', 'Grasshopper', 'Ant', 'Beetle'}\n",
      "Success! Saved (5353, 512) matrix to data/embs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kairos_clean_embeddings, kairos_clean_labels, kairos_clean_file_paths = generate_clean_embs(kairos_clean_data, 'kairos_clean', OUT_DIR)\n",
    "test_clean_embeddings, test_clean_labels, test_clean_file_paths = generate_clean_embs(test_clean_data, 'test_clean', OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff52d1-91c0-4e7e-b899-ee2ac1b0ca6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
