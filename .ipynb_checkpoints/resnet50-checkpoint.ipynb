{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec46e862",
   "metadata": {},
   "source": [
    "## Run Baseline ResNet-50 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0461c547",
   "metadata": {},
   "source": [
    "TASK: Detect Insect Type \\\n",
    "Dataset: iNaturalist \\\n",
    "Model: Resnet-50 (pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b3b002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install datasets\n",
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0499076d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-25 07:23:34.886840: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-25 07:23:34.886939: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-25 07:23:34.931696: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-25 07:23:35.027486: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import peft\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from utils.label_mappings import iNat_to_clean_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3544062d",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860b700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/sxj1215/inaturalist\n",
    "dataset = load_dataset(\"sxj1215/inaturalist\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "862b7bc1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "image file is truncated (122 bytes not processed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m img_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moriginal_label\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moriginal_label\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miNat_to_clean_map\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py:2372\u001b[0m, in \u001b[0;36mDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2370\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(pa_subtable\u001b[38;5;241m.\u001b[39mnum_rows):\n\u001b[1;32m   2371\u001b[0m             pa_subtable_ex \u001b[38;5;241m=\u001b[39m pa_subtable\u001b[38;5;241m.\u001b[39mslice(i, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 2372\u001b[0m             formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2373\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpa_subtable_ex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2374\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2375\u001b[0m \u001b[43m                \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2376\u001b[0m \u001b[43m                \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2377\u001b[0m \u001b[43m                \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_all_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2378\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2379\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m formatted_output\n\u001b[1;32m   2380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/formatting/formatting.py:639\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    637\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/formatting/formatting.py:403\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/formatting/formatting.py:444\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    443\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[0;32m--> 444\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/formatting/formatting.py:222\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m row\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/features/features.py:2044\u001b[0m, in \u001b[0;36mFeatures.decode_example\u001b[0;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[1;32m   2032\u001b[0m \n\u001b[1;32m   2033\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2041\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[1;32m   2042\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[1;32m   2045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2046\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_column_requires_decoding\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2047\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\n\u001b[1;32m   2048\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mzip_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2049\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\n\u001b[1;32m   2050\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/features/features.py:2045\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[1;32m   2032\u001b[0m \n\u001b[1;32m   2033\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2041\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[1;32m   2042\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m-> 2045\u001b[0m         column_name: \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2046\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   2047\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[1;32m   2048\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[1;32m   2049\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[1;32m   2050\u001b[0m         )\n\u001b[1;32m   2051\u001b[0m     }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/features/features.py:1380\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _check_non_null_non_empty_recursive(first_elmt, sub_schema):\n\u001b[1;32m   1379\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_elmt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m first_elmt:\n\u001b[1;32m   1381\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [decode_nested_example(sub_schema, o) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(obj)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/features/features.py:1405\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (Audio, Image, Video)):\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m schema\u001b[38;5;241m.\u001b[39mdecode:\n\u001b[0;32m-> 1405\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/features/image.py:188\u001b[0m, in \u001b[0;36mImage.decode_example\u001b[0;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(BytesIO(bytes_))\n\u001b[0;32m--> 188\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mgetexif()\u001b[38;5;241m.\u001b[39mget(PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mExifTags\u001b[38;5;241m.\u001b[39mBase\u001b[38;5;241m.\u001b[39mOrientation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImageOps\u001b[38;5;241m.\u001b[39mexif_transpose(image)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/PIL/ImageFile.py:290\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    287\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage file is truncated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(b)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes not processed)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m         )\n\u001b[0;32m--> 290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m    293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n",
      "\u001b[0;31mOSError\u001b[0m: image file is truncated (122 bytes not processed)"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "rows = []\n",
    "img_id = 0\n",
    "\n",
    "for row in dataset:\n",
    "    original_label = row[\"messages\"][1][\"content\"]\n",
    "\n",
    "    if original_label not in iNat_to_clean_map:\n",
    "        continue  # skip unmapped species (?), should there be a different OTHER class\n",
    "\n",
    "    clean_label = iNat_to_clean_map.get(original_label, original_label)\n",
    "\n",
    "    image_path = f\"images/{img_id}.jpg\"\n",
    "    row[\"images\"][0].save(image_path)\n",
    "\n",
    "    rows.append(f\"{image_path},{clean_label}\")\n",
    "    img_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d2c4a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"labels.csv\", \"w\") as f:\n",
    "    f.write(\"image,label\\n\")\n",
    "    f.write(\"\\n\".join(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d4b12",
   "metadata": {},
   "source": [
    "Custom Dataset Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b3e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses RandomResizedCrop, RandomHorizontalFlip to help model generalize\n",
    "# applies standard ImageNet normalization\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66941fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom PyTorch Dataset class to load images and convert labels to integers\n",
    "\n",
    "class JPGDataset(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "        self.data = data_df  # now accepts a df directly\n",
    "        self.transform = transform\n",
    "\n",
    "        # map label strings to integers\n",
    "        self.classes = sorted(self.data.label.unique())\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image = Image.open(row.image).convert(\"RGB\")\n",
    "        label = self.class_to_idx[row.label]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b51247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00e307ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4412845-553a-4b79-afdb-f3a94a4e4cc4",
   "metadata": {},
   "source": [
    "### Model Architecture/Training (random sample, cross-val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f69bf966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Fold 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/dsenthil/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 198MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train=0.736, val=0.940\n",
      "Epoch 2: train=0.909, val=0.935\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1: train=0.715, val=0.919\n",
      "Epoch 2: train=0.897, val=0.927\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1: train=0.740, val=0.952\n",
      "Epoch 2: train=0.892, val=0.940\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1: train=0.705, val=0.895\n",
      "Epoch 2: train=0.904, val=0.935\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1: train=0.761, val=0.960\n",
      "Epoch 2: train=0.885, val=0.951\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "df = pd.read_csv(\"labels.csv\")\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_accuracies = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "    print(f\"\\n--- Starting Fold {fold + 1}/5 ---\")\n",
    "    \n",
    "    # create df for eacg fold\n",
    "    train_df = df.iloc[train_idx]\n",
    "    val_df = df.iloc[val_idx]\n",
    "    \n",
    "    # initialize datasets and loaders\n",
    "    train_dataset = JPGDataset(train_df, transform=train_transforms)\n",
    "    val_dataset   = JPGDataset(val_df, transform=val_transforms)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    num_classes = len(train_dataset.classes)\n",
    "\n",
    "    # re-initialize the model for every fold to prevent weight leakage\n",
    "    model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # freeze backbone weights and unfreeze the new head\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)\n",
    "\n",
    "    # train for 2 epochs per fold\n",
    "    for epoch in range(2):\n",
    "        train_acc = train_one_epoch(model, train_loader)\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        print(f\"Epoch {epoch+1}: train={train_acc:.3f}, val={val_acc:.3f}\")\n",
    "    \n",
    "    fold_accuracies.append(val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d57722c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average 5-Fold Accuracy: 0.938\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAverage 5-Fold Accuracy: {np.mean(fold_accuracies):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7d1f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final weights and class names\n",
    "torch.save({\n",
    "    \"model\": model.state_dict(),\n",
    "    \"classes\": train_dataset.classes\n",
    "}, \"resnet50_insects_cv.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b8e02c-c32b-4e8d-8f92-c35183987e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8c1b84e-626b-4535-81f5-91b7a2331e0d",
   "metadata": {},
   "source": [
    "### LoRA Optimized Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8afda1-56e7-4da1-8ee0-d4123122fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labels.csv\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"conv1\"],\n",
    "    lora_dropout=0.1,\n",
    "    modules_to_save=[\"fc\"] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41a593de-c9e7-4b12-8603-4cdf1f5ccaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Fold 1/5 ---\n",
      "Fold 1, Epoch 1: Train Acc=0.721, Val Acc=0.895\n",
      "Fold 1, Epoch 2: Train Acc=0.914, Val Acc=0.968\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Fold 2, Epoch 1: Train Acc=0.726, Val Acc=0.931\n",
      "Fold 2, Epoch 2: Train Acc=0.921, Val Acc=0.972\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Fold 3, Epoch 1: Train Acc=0.732, Val Acc=0.931\n",
      "Fold 3, Epoch 2: Train Acc=0.910, Val Acc=0.980\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Fold 4, Epoch 1: Train Acc=0.718, Val Acc=0.895\n",
      "Fold 4, Epoch 2: Train Acc=0.899, Val Acc=0.976\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Fold 5, Epoch 1: Train Acc=0.748, Val Acc=0.968\n",
      "Fold 5, Epoch 2: Train Acc=0.918, Val Acc=0.976\n"
     ]
    }
   ],
   "source": [
    "# 5-fold cross val loop\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "    print(f\"\\n--- Starting Fold {fold + 1}/5 ---\")\n",
    "    \n",
    "    train_df = df.iloc[train_idx]\n",
    "    val_df = df.iloc[val_idx]\n",
    "    \n",
    "    train_dataset = JPGDataset(train_df, transform=train_transforms)\n",
    "    val_dataset = JPGDataset(val_df, transform=val_transforms)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    base_model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "    base_model.fc = nn.Linear(base_model.fc.in_features, len(train_dataset.classes)) \n",
    "    model = get_peft_model(base_model, lora_config).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(2):\n",
    "        train_acc = train_one_epoch(model, train_loader)\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        print(f\"Fold {fold+1}, Epoch {epoch+1}: Train Acc={train_acc:.3f}, Val Acc={val_acc:.3f}\")\n",
    "\n",
    "    fold_results.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7b8b756-08fe-4642-aa46-57cac7d04b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final 5-Fold Mean Accuracy: 0.9742\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFinal 5-Fold Mean Accuracy: {np.mean(fold_results):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec34f2-a1f3-4f2c-af16-25cf1715943b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84b56329",
   "metadata": {},
   "source": [
    "### Model Architecture/Training (random sample, no cross-val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b89a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labels.csv\")\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df.label,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "val_df.to_csv(\"val.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff2b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = JPGDataset(\"train.csv\", transform=train_transforms)\n",
    "val_dataset   = JPGDataset(\"val.csv\", transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02227c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# load the pre-trained resnet50 model\n",
    "model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "# replace the final layer with new layer with the number of insect classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d847cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0239dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the backbone weights of the ResNet are frozen\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# only the new final layer will be updated during the training (fine-tuning step 1)\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64816571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model trained using Adam optimizer and CrossEntropyLoss\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.fc.parameters(),\n",
    "    lr=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffb2954b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train=0.767, val=0.927\n",
      "Epoch 2: train=0.891, val=0.956\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc = train_one_epoch(model, train_loader)\n",
    "    val_acc = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: train={train_acc:.3f}, val={val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df43e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final weights and class names\n",
    "\n",
    "torch.save({\n",
    "    \"model\": model.state_dict(),\n",
    "    \"classes\": train_dataset.classes\n",
    "}, \"resnet50_insects.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4565123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
