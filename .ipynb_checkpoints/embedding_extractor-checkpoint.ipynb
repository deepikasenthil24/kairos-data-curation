{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27963141",
   "metadata": {},
   "source": [
    "### Extract Embeddings\n",
    "\n",
    "Based on https://github.com/rom1504/clip-retrieval\n",
    "\n",
    "First, pip install clip-retrieval\n",
    "\n",
    "`pip install git+https://github.com/openai/CLIP.git`\n",
    "\n",
    "TODO:\n",
    "- labels need to be npy (check if they're needed)\n",
    "- split iNat embedding files to train (80% for Kairos) and test (20% for ResNet)\n",
    "- need to check iNat ids after shuffle and split\n",
    "\n",
    "order: Need to give unique ID (idx), then split by noise / clean, then shuffle clean, then split clean 80 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7751b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "#from datasets import Image as DatasetsImage #conflicts with PIL Image\n",
    "import pandas as pd\n",
    "from utils.label_mappings import *\n",
    "\n",
    "OUT_DIR = 'data/embs'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8f4a8-bac4-49f0-9376-8f790ef30eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ea5e9",
   "metadata": {},
   "source": [
    "#### iNaturalist Embeddings\n",
    "Need to get embeddings for all images in iNat dataset (3.3GB) for Kairos to curate the insects from the rest (noisy). 36355 rows/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iNat data\n",
    "iNat36 = load_dataset(\"sxj1215/inaturalist\", split='train') #36k rows #3.3 GB\n",
    "ids = list(range(len(iNat36)))\n",
    "iNat36 = iNat36.add_column(\"id\", ids) #not idempotent\n",
    "iNat36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7273ed-5bdb-4cf0-87d2-fa2365cfe121",
   "metadata": {},
   "outputs": [],
   "source": [
    "iNat36_label_df = pd.DataFrame({'messages': iNat36['messages'], 'id': iNat36['id']})\n",
    "def get_iNat_label(messages):\n",
    "    return messages[1]['content']\n",
    "iNat36_label_df['species'] = iNat36_label_df['messages'].apply(get_iNat_label)\n",
    "def map_inat_to_clean_label(label):\n",
    "    if label in iNat_to_clean_map:\n",
    "        return iNat_to_clean_map[label]\n",
    "    else:\n",
    "        return 'noise'\n",
    "iNat36_label_df['clean_label'] = iNat36_label_df['species'].apply(map_inat_to_clean_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fb732a-f60a-4672-968c-bd16a18bc6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to shuffle and train test split iNat36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21d054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inat_embs(inat_split_ds, file_prefix, out_dir):\n",
    "    '''\n",
    "    inat_split_ds is a split (train, test) of the iNat dataset\n",
    "    \n",
    "    file_prefix is a string to clearly label files and distinguish different groups of embeddings\n",
    "    such as 'train_inat' or 'test_inat' \n",
    "\n",
    "    out_dir is the directory the data will be saved to\n",
    "    '''\n",
    "    embs = []\n",
    "    labels = []\n",
    "    row_ids = []\n",
    "\n",
    "    for i in tqdm(range(len(inat_split_ds))):\n",
    "        try:\n",
    "            row = inat_split_ds[i]\n",
    "            row_id = row['id']\n",
    "            img = row[\"images\"][0]\n",
    "            img = preprocess(img).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                feats = model.encode_image(img)\n",
    "                feats /= feats.norm(dim=-1, keepdim=True)\n",
    "            embs.append(feats.cpu().numpy())\n",
    "            labels.append(iNat36_label_df.iloc[idx][\"clean_label\"]) ## TODO: figure out how to match pandas df with labels to hf ds with images after shuffling\n",
    "            row_ids.append(row_id)\n",
    "        except Exception as e:\n",
    "            embs.append(np.zeros(512).reshape(1, 512)) #need to add placeholder so entries line up later\n",
    "            labels.append('skip')\n",
    "            row_ids.append(row_id)\n",
    "            continue\n",
    "    \n",
    "    print(f\"Successfully processed {len(embs)} examples\")\n",
    "\n",
    "    if embs:\n",
    "        emb_matrix = np.vstack(embs)\n",
    "        \n",
    "        np.save(os.path.join(OUT_DIR, f\"{file_prefix}_embeddings.npy\"), emb_matrix)\n",
    "        np.save(os.path.join(OUT_DIR, f\"{file_prefix}_labels.npy\"), labels)\n",
    "        \n",
    "        with open(os.path.join(OUT_DIR, f\"{file_prefix}_row_ids.txt\"), \"w\") as f:\n",
    "            f.write(\"\\n\".join(row_ids))\n",
    "            \n",
    "        print(f\"Success! Saved {emb_matrix.shape} matrix to {OUT_DIR}\")\n",
    "\n",
    "\n",
    "    return embs, labels, row_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb059322-3b22-4c7a-a871-822702b8591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inat_embeddings, inat_labels, inat_row_ids = generate_inat_embs(iNat36, 'full_inat', OUT_DIR)\n",
    "\n",
    "# should run these if we train-test split iNat:\n",
    "# inat_embeddings, inat_labels, inat_idxs = generate_inat_embs(iNat36_train, 'train_inat', OUT_DIR)\n",
    "# inat_embeddings, inat_labels, inat_idxs = generate_inat_embs(iNat36_test, 'test_inat', OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b72a60-7614-4905-ad6d-61d0f9e05b1e",
   "metadata": {},
   "source": [
    "#### Kaggle clean embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce590df-ac02-44a8-ab01-6f5c5bfb0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sample_clean_data import kairos_clean_data, test_clean_data # stratefied random sampled data, rest of data\n",
    "label_pos_in_path = 2\n",
    "\n",
    "\n",
    "def generate_clean_embs(images_var, file_prefix, out_dir):\n",
    "    '''\n",
    "    images var is a list of filepaths and is defined in sample_clean_data.py\n",
    "    \n",
    "    file_prefix is a string to clearly label files and distinguish different groups of embeddings\n",
    "    such as 'kairos_clean' or 'test_clean' \n",
    "\n",
    "    out_dir is the directory the data will be saved to\n",
    "    '''\n",
    "    embs = []\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "\n",
    "    for path in tqdm(images_var): # path = data/clean_insect_images/Ant/Ant_283.jpg\n",
    "        try:\n",
    "            image = preprocess(Image.open(path)).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                features = model.encode_image(image)\n",
    "                features /= features.norm(dim=-1, keepdim=True)    # normalize for cosine similarity\n",
    "                \n",
    "            embs.append(features.cpu().numpy())\n",
    "            labels.append(path.split('/')[label_pos_in_path])\n",
    "            filepaths.append(path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping corrupt image {path}: {e}\")\n",
    "    \n",
    "    print(f\"Successfully processed {len(embs)} examples\")\n",
    "    \n",
    "    if embs:\n",
    "        emb_matrix = np.vstack(embs)\n",
    "        \n",
    "        np.save(os.path.join(OUT_DIR, f\"{file_prefix}_embeddings.npy\"), emb_matrix)\n",
    "        np.save(os.path.join(OUT_DIR, f\"{file_prefix}_labels.npy\"), kairos_clean_labels)\n",
    "        \n",
    "        with open(os.path.join(OUT_DIR, f\"{file_prefix}_filepaths.txt\"), \"w\") as f:\n",
    "            f.write(\"\\n\".join(filepaths))\n",
    "            \n",
    "        print(f\"Success! Saved {emb_matrix.shape} matrix to {OUT_DIR}\")\n",
    "\n",
    "\n",
    "    return embs, labels, filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4449eb4-d4e6-40df-b614-85986944114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_clean_embs(kairos_clean_data, 'kairos_clean', OUT_DIR)\n",
    "generate_clean_embs(test_clean_data, 'test_clean', OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff52d1-91c0-4e7e-b899-ee2ac1b0ca6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
