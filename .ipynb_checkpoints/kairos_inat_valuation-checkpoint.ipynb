{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a899477c-68ad-4781-adc3-15b1514c51ce",
   "metadata": {},
   "source": [
    "# KAIROS valuation of iNaturalist subset using clean insect data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f70e9a2-f987-4669-808c-f3defa2a94b5",
   "metadata": {},
   "source": [
    "https://github.com/lodino/kairos/blob/main/examples/image-data.ipynb \n",
    "\n",
    "#### TODO\n",
    "- Currently just transferred code from Q1 experiments on adult income dataset. Will adapt for the clean insect data (validation) and iNaturalist dataset (training/messy).\n",
    "- Make output the top X highest valued images from the inaturalist dataset (only the insects as theoretically labeled by humans) to use for finetuning ResNet-50.\n",
    "\n",
    "Collecting \"noisy\" indexes: if label is not one of the species in our main insect categories, it is noisy. We might create a semi-noisy label for images that are insects but are just not ones we are looking for. Since the method could value them as \"clean\" and it wouldn't be totally wrong, we just want to know how accurate Kairos is being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fdcd8e70-3afd-4e34-ba4d-1259139382dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import opendataval\n",
    "from opendataval.experiment import ExperimentMediator\n",
    "from opendataval.dataval.api import DataEvaluator, ModelLessMixin\n",
    "from opendataval.dataval import DataOob, LavaEvaluator, DVRL\n",
    "from opendataval.experiment import discover_corrupted_sample, noisy_detection\n",
    "from opendataval.dataloader import Register, DataFetcher, mix_labels, add_gauss_noise\n",
    "from opendataval.model import ClassifierMLP, LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "import utils.custom_valuations\n",
    "import utils\n",
    "\n",
    "import importlib\n",
    "importlib.reload(utils.custom_valuations)\n",
    "importlib.reload(utils)\n",
    "\n",
    "from utils.custom_valuations import *\n",
    "from utils import *\n",
    "#from fixed_valuations import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "PATH_TO_DATA=\"data_files\" #change based on working directory\n",
    "\n",
    "markers = {\n",
    "    'DataOob': 'o',\n",
    "    'KNNShapley': 's',\n",
    "    'FixedKNNShapley': 's',\n",
    "    'FixedLavaEvaluator': 'x',\n",
    "    #'LavaEvaluator': 'x',\n",
    "    'DVRL': 'x',\n",
    "    'Kairos': '^',\n",
    "}\n",
    "\n",
    "def write_dict(d, fname):\n",
    "    txt = json.dumps(d)\n",
    "    with open(f'logs/{fname}.json', 'w+') as f:\n",
    "        f.write(txt)\n",
    "        \n",
    "train_count, valid_count, test_count = ...,...,...\n",
    "train_kwargs = {\"epochs\": 3, \"batch_size\": 100, \"lr\": 0.01}\n",
    "metric_name = ... #'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51a8979d-1ed6-46e2-a51c-0e0a0e622edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n",
      "[8]\n",
      "[0. 1.]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "def encode_labels(train_labels, valid_labels):\n",
    "    all_labels = np.unique(np.concatenate([train_labels, valid_labels]))\n",
    "    all_labels = np.unique(np.concatenate([train_labels, valid_labels]))\n",
    "    num_classes = len(all_labels)\n",
    "    label2id = {label: i for i, label in enumerate(all_labels)}\n",
    "    id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "    train_ids = np.array([label2id[l] for l in train_labels], dtype=np.int64)\n",
    "    valid_ids = np.array([label2id[l] for l in valid_labels], dtype=np.int64)\n",
    "\n",
    "    return train_ids, valid_ids, label2id, id2label, num_classes\n",
    "\n",
    "\n",
    "def load_inat_data(): \n",
    "    train_labels = np.load(\"data/embs/inat_labels.npy\")[:36355].copy()\n",
    "    valid_labels = np.load(\"data/embs/kairos_clean_labels.npy\")[:36355].copy()\n",
    "\n",
    "    train_ids, valid_ids, label2id, id2label, num_classes = encode_labels(\n",
    "        train_labels, valid_labels\n",
    "    )\n",
    "    \n",
    "    #num_classes = 9#len(label2id)\n",
    "    \n",
    "    # One-hot encode the labels for CIFAR-10 (10 classes)\n",
    "    #num_classes = max(len(np.unique(train_labels)), len(np.unique(valid_labels))) #9 ##### categories + noise # Should this just be every species? Would go up to ~200 classes. \n",
    "    ### Can we try without labels first?\n",
    "    # # Flatten labels if necessary (in case shape is (N,1))\n",
    "    # if labels.ndim > 1 and labels.shape[1] == 1:\n",
    "    #     labels = labels.flatten()\n",
    "    \n",
    "    # 1. Set training set.\n",
    "    x_train = np.load(\"data/embs/inat_embeddings.npy\")[:36355]  # for some reason the len is double what it should be, maybe issue with embedding generator # clean embeddings for training\n",
    "    #y_train = np.eye(num_classes)[train_ids] #one hot encode labels\n",
    "    y_train = np.array([label2id[l] for l in train_labels], dtype=int)\n",
    "\n",
    "    # print(len(x_train), len(y_train))\n",
    "    \n",
    "    # 2. Set validation set.\n",
    "    x_valid = np.load(\"data/embs/kairos_clean_embeddings.npy\")[:36355]\n",
    "    #y_valid = np.eye(num_classes)[valid_ids] #one hot encode labels\n",
    "    y_valid = np.array([label2id[l] for l in valid_labels], dtype=int)\n",
    "\n",
    "    x_test = x_valid[:1]\n",
    "    y_test = y_valid[:1]\n",
    "\n",
    "    # print('Shapes:')\n",
    "    # print(y_valid[1])\n",
    "    # print(y_train[0].shape, y_valid[0].shape)\n",
    "    # print(y_train.shape, y_valid.shape)\n",
    "    # print(y_valid[:10])\n",
    "    print(np.unique(y_valid))\n",
    "    print(np.unique(y_train))\n",
    "\n",
    "    # One-hot encode\n",
    "    y_train = np.eye(num_classes)[y_train]\n",
    "    y_valid = np.eye(num_classes)[y_valid]\n",
    "    y_test  = np.eye(num_classes)[y_test]\n",
    "\n",
    "    print(np.unique(y_valid))\n",
    "    print(np.unique(y_train))\n",
    "    \n",
    "    #fetcher.noisy_train_indices = np.load(\"../data/embs/inat_noise_indexes.npy\").copy()\n",
    "    \n",
    "    covariates = (x_train, x_valid, x_test)\n",
    "    labels = (y_train, y_valid, y_test)\n",
    "\n",
    "    return covariates, labels\n",
    "\n",
    "\n",
    "\n",
    "Register(\n",
    "        dataset_name=f\"iNat\",\n",
    "        one_hot=False,\n",
    "        cacheable=False,\n",
    "        presplit=True\n",
    "    )(lambda: load_inat_data())\n",
    "\n",
    "fetcher = DataFetcher(\"iNat\")\n",
    "\n",
    "\n",
    "\n",
    "# # Set test set.\n",
    "# fetcher.x_test = clean_embeddings[train_count + valid_count:train_count + valid_count + test_count].copy()\n",
    "# fetcher.y_test = onehot_labels[train_count + valid_count:train_count + valid_count + test_count].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2276dddd-e746-4fbe-9544-80eeaa0c25b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (36355,9) (36355,8) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Estimate kernel bandwidth w/ median sample pairwise distance\u001b[39;00m\n\u001b[1;32m      2\u001b[0m kairos \u001b[38;5;241m=\u001b[39m Kairos()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mkairos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m sigma_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(est_median_dist(kairos\u001b[38;5;241m.\u001b[39mX_valid\u001b[38;5;241m.\u001b[39mnumpy()), est_median_dist(kairos\u001b[38;5;241m.\u001b[39mX_train\u001b[38;5;241m.\u001b[39mnumpy()))\n",
      "File \u001b[0;32m~/kairos-data-curation/utils/custom_valuations.py:119\u001b[0m, in \u001b[0;36mKairos.input_data\u001b[0;34m(self, x_train, y_train, x_valid, y_valid)\u001b[0m\n\u001b[1;32m    109\u001b[0m     p_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier\u001b[38;5;241m.\u001b[39mpredict_proba(x_train)\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# Ensure y_train is one-hot for residual computation\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# if y_train.ndim == 1:\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m#     num_classes = p_train.shape[1]\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m#     y_train_oh = np.eye(num_classes)[y_train]\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m#    y_train_oh = y_train\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     r_train \u001b[38;5;241m=\u001b[39m \u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp_train\u001b[49m \n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(r_train, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (36355,9) (36355,8) "
     ]
    }
   ],
   "source": [
    "# Estimate kernel bandwidth w/ median sample pairwise distance\n",
    "kairos = Kairos()\n",
    "kairos.input_data(fetcher.x_train, fetcher.y_train, fetcher.x_valid, fetcher.y_valid)\n",
    "sigma_feature = max(est_median_dist(kairos.X_valid.numpy()), est_median_dist(kairos.X_train.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85e95d2-1c05-4c5e-bae9-f220c407a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = LogisticRegression(input_dim=len(fetcher.x_train[0]), num_classes=len(fetcher.y_train[0]))\n",
    "exper_med = ExperimentMediator(fetcher=fetcher, pred_model=model_name, train_kwargs=train_kwargs,\n",
    "                               metric_name=metric_name, raises_error=True)\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "list_of_data_evaluators = [\n",
    "    FixedKNNShapley(),\n",
    "    DataOob(num_models=10), LavaEvaluator(random_state=42),\n",
    "    Kairos(sigma_feature=sigma_feature, lambda_weight=.97),\n",
    "]\n",
    "eval_med = exper_med.compute_data_values(list_of_data_evaluators)\n",
    "all_d = dict()\n",
    "for evaluator in eval_med.data_evaluators:\n",
    "    d = get_discover_corrupted_sample_results(evaluator, fetcher)\n",
    "    eval_name = evaluator.__class__.__name__\n",
    "    all_d[eval_name] = d\n",
    "    plt.plot(d['axis'], d['corrupt_found'], marker=markers[eval_name], label=eval_name)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "for ax in fig.axes:\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')\n",
    "fig.supylabel('% covered corrupted data')\n",
    "fig.supxlabel('% inspected data')\n",
    "fig.suptitle(f'CIFAR-10 Dataset ({len(fetcher.x_train)} train, {len(fetcher.x_valid)} valid, feature noise)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a30b4bf-c572-40f2-8e23-85f59bd82a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b2225a-7c6c-4db6-b398-0a4ef79a05f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot accuracy\n",
    "def plot_valuations(eval_name, eval_med, fetcher, dataset_name, exp_num):\n",
    "\n",
    "    evalu = None\n",
    "    for evaluator in eval_med.data_evaluators:\n",
    "            if evaluator.__class__.__name__ == eval_name:\n",
    "                    evalu = evaluator\n",
    "                    break\n",
    "\n",
    "    if evalu is None:\n",
    "            raise RuntimeError(f\"{eval_name} evaluator not found in eval_med\")\n",
    "\n",
    "    valuations = evalu.data_values  # length = n_train\n",
    "\n",
    "    # Identify noisy vs clean indices\n",
    "    noisy_idxs = np.array(fetcher.noisy_train_indices)\n",
    "    clean_idxs = np.setdiff1d(np.arange(len(valuations)), noisy)\n",
    "\n",
    "    vals_noisy = valuations[noisy_idxs]\n",
    "    vals_clean = valuations[clean_idxs]\n",
    "    print(len(vals_clean), len(vals_noisy))\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "\n",
    "    # Histogram curves \n",
    "    plt.hist(vals_clean, bins=50, density=True, histtype='step', linewidth=2, label=\"Clean\", color='blue')\n",
    "    plt.hist(vals_noisy, bins=50, density=True, histtype='step', linewidth=2, label=\"Noisy\", color='red')\n",
    "\n",
    "    # KDE smooth curves \n",
    "    # from scipy.stats import gaussian_kde\n",
    "    # xs = np.linspace(min(valuations), max(valuations), 500)\n",
    "    # plt.plot(xs, gaussian_kde(vals_clean)(xs), label=\"Clean KDE\", color='blue')\n",
    "    # plt.plot(xs, gaussian_kde(vals_noisy)(xs), label=\"Noisy KDE\", color='red')\n",
    "\n",
    "    plt.xlabel(f\"{eval_name} Valuation Score\")\n",
    "    plt.ylabel(\"Frequency (Density)\")\n",
    "    plt.title(f\"{eval_name} {dataset_name} Valuations: Clean vs Noisy (Exp {exp_num})\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def thresh_acc(eval_name, eval_med, dataset_name, exp_num, fetcher):\n",
    "    evalu = None\n",
    "    for evaluator in eval_med.data_evaluators:\n",
    "        if evaluator.__class__.__name__ == eval_name:\n",
    "            evalu = evaluator\n",
    "            break\n",
    "\n",
    "    if evalu is None:\n",
    "        raise RuntimeError(f\"{eval_name} evaluator not found in eval_med\")\n",
    "\n",
    "    valuations = evalu.data_values\n",
    "    \n",
    "    vals = valuations.reshape(-1,1)\n",
    "    gmm = GaussianMixture(n_components=2, random_state=42).fit(vals)\n",
    "\n",
    "    # responsibilities: P(component k | v_i)\n",
    "    probs = gmm.predict_proba(vals)\n",
    "\n",
    "    # Determine which component = noisy (lower mean)\n",
    "    means = gmm.means_.reshape(-1)\n",
    "    noisy_component = np.argmin(means)  \n",
    "\n",
    "    # threshold = decision boundary between gaussians\n",
    "    threshold = np.mean([\n",
    "        means[noisy_component],\n",
    "        means[1-noisy_component]\n",
    "    ])\n",
    "    \n",
    "    print(f\"{eval_name} {dataset_name} experiment {exp_num}\")\n",
    "    print(\"GMM threshold:\", round(threshold, 4))\n",
    "\n",
    "    pred = (valuations < threshold).astype(int)  \n",
    "\n",
    "    y_true = np.zeros(len(valuations), dtype=int)\n",
    "    y_true[fetcher.noisy_train_indices] = 1  # 1 = real noisy\n",
    "\n",
    "    accuracy = round((pred == y_true).mean(), 4)\n",
    "\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "    precision = round(precision_score(y_true, pred), 4)\n",
    "    recall = round(recall_score(y_true, pred), 4)\n",
    "    f1 = round(f1_score(y_true, pred), 4)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 score:\", f1)\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f58732-69aa-4457-b32d-95cab6433a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(dataset_name, exp_num, data_frac, path_to_data):\n",
    "\n",
    "    Register(\n",
    "        dataset_name=f\"{dataset_name}_experiment{exp_num}\",\n",
    "        one_hot=False,\n",
    "        cacheable=False,\n",
    "        presplit=True\n",
    "    )(lambda: load_presplit_dataset(dataset_name, exp_num, data_frac, path_to_data))#(load_presplit_dataset(dataset_name, exp_num, data_frac, path_to_data))\n",
    "\n",
    "    fetcher = DataFetcher(f\"{dataset_name}_experiment{exp_num}\")\n",
    "    fetcher.noisy_train_indices = [i for i in noisy_indexes[f\"exp{exp_num}\"] if i < len(fetcher.x_train)]\n",
    "    curr_noisy_idxs = sum(np.array(fetcher.noisy_train_indices) < len(fetcher.x_train))\n",
    "\n",
    "    # Estimate kernel bandwidth w/ median sample pairwise distance\n",
    "    kairos = Kairos()\n",
    "    kairos.input_data(fetcher.x_train, fetcher.y_train, fetcher.x_valid, fetcher.y_valid)\n",
    "    sigma_feature = max(est_median_dist(kairos.X_valid.numpy()), est_median_dist(kairos.X_train.numpy()))\n",
    "\n",
    "    ### plot Covered vs Inspected data\n",
    "    model_name = LogisticRegression(input_dim=len(fetcher.x_train[0]), num_classes=(int(np.max(fetcher.y_train)) + 1)) #Used to be fetcher.y_train[0].size\n",
    "    exper_med = ExperimentMediator(fetcher=fetcher, pred_model=model_name, train_kwargs=train_kwargs,\n",
    "                                metric_name=metric_name, raises_error=True)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    list_of_data_evaluators = [\n",
    "        FixedKNNShapley(),\n",
    "        DataOob(num_models=10),\n",
    "        #LavaEvaluator(random_state=42), #breaks if dataset too big\n",
    "        Kairos(sigma_feature=sigma_feature, lambda_weight=.97),\n",
    "    ]\n",
    "    eval_med = exper_med.compute_data_values(list_of_data_evaluators)\n",
    "\n",
    "    for evaluator in eval_med.data_evaluators:\n",
    "        d = get_discover_corrupted_sample_results(evaluator, fetcher)\n",
    "        eval_name = evaluator.__class__.__name__\n",
    "        plt.plot(d['axis'], d['corrupt_found'], marker=markers[eval_name], label=eval_name)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    for ax in fig.axes:\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_xlabel('')\n",
    "    fig.supylabel('% covered corrupted data')\n",
    "    fig.supxlabel('% inspected data')\n",
    "    fig.suptitle(f'Kairos: {dataset_name} ({len(fetcher.x_train)} train, {len(fetcher.x_valid)} valid, {curr_noisy_idxs} label noise) Exp 2')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    plot_valuations(\"Kairos\", eval_med, fetcher, dataset_name, exp_num)\n",
    "\n",
    "    thresh_acc(\"Kairos\", eval_med, dataset_name, exp_num, fetcher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f4ea95-f447-437e-a9a6-79a3248b7ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(dataset_name=\"adult\", exp_num=2, data_frac=0.35, path_to_data=PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f28b96-5175-433c-9588-009f42327c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kairos",
   "language": "python",
   "name": "kairos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
